*Ejercicio 1* RISC-V maneja el principio de simplicidad, en relación a esto responda:
 - ¿Hacer un desplazamiento en un registro es más rápido que buscar el valor que se ha de
desplazar en memoria?
 - A partir del inciso anterior, ¿qué habría de tener en cuenta a la hora de revisar el rendimiento
de su programa?

Respuesta:
Operar con un valor en un registro siempre va a ser más rápido que con un valor en memoria ya que el
primero es parte interna de la CPU, por ende está más cerca, no se usan buses y es probable que se
ahorren ticks de reloj.
Buena parte del rendimiento de un programa se debe a cuánto se aprovecha la utilización de registros
y cuánto se evita buscar en memoria. Es por esto que RISC-V se diseñó con grandes cantidades de
registros, para que los programadores no estén necesitando ir a memoria cuando no haya más
registros disponibles.
Se puede comparar con la arquitectura Orga1 que contiene 8 registros, mientras que RISC-V tiene 32,
así que si existe un programa que utiliza mucha memoria, seguramente en RISC-V al programarlo
sea mucho más rápido ya que hay más registros para aprovechar.

*Ejercicio 2* Explique de qué modo se resuelven los saltos incondicionales. ¿Qué sucede con el
valor de retorno?

Respuesta:
RISC-V resuelve los saltos incondicionales principalmente con dos instrucciones: jal y jalr.
Sea rd y rs1 registros, y offset un valor inmediato, así se comportarían:

jal:  rd <- pc + 4; pc <- pc  + sign_ext(offset)
jalr: rd <- pc + 4; pc <- rs1 + sign_ext(offset)

(No entiendo por qué en la guía pc + 4 se considera como la siguiente instrucción y no
simplemente pc, se supone que en el Fetch el pc ya está +4, además que las instrucciones
tienen tamaño fijo)

Si repasamos la arquitectura de Orga1 vemos que son instrucciones muy parecidas al JMP y al CALL,
como si fuesen una combinación. En ambas instrucciones, primero se guarda la dirección de la
siguiente instrucción en rd, como en el caso de CALL que guarda el pc en el stack.
Luego se le suma al pc el offset, más el valor de rs1 en caso de jalr; este paso imita al
comportamiento del JMP.

Por default si rd no está definido, se asume que el pc se guarda en ra, un registro dedicado al
valor de retorno que sirve cuando se llaman funciones.

Por como están diseñadas estas instrucciones, son lo suficientemente flexibles como para poder
imitar el comportamiento del JMP, CALL, y encima el RET también. Para no extender mucho,
muestro solamente el de JMP, ya que CALL y RET usan el stack y tengo que usar otras instrucciones:

JMP: jalr x0, offset, rs1

Ignorando el offset y el rs1, se ve que se quiere guardar el pc en x0, pero RISC-V utiliza ese
registro especialmente como constante 0, por lo que no se hace nada y sólo se asigna un nuevo valor
al pc.

*Ejercicio 3* ¿Qué significa que la arquitectura RISC-V sea modular? ¿Qué ventajas puede tener
esto?

Respuesta:
Antes de que se explique en la guía sobre por qué RISC-V es una arquitectura modular, primero se 
repasa la evolución que ha tenido la arquitectura x86 desde sus comienzos hasta estos días, al ser
un caso bastante extremo.
Sabiendo que uno de los objetivos de Intel es permitir que programas viejos puedan ser ejecutados
en nuevos procesadores, se decidió que los mismos siempre mantengan las instrucciones de los
procesadores anteriores. Es decir, el set de instrucciones del x86 se agrandó con el paso del
tiempo desde el procesador 8086 de forma exponencial.
Esta decisión presenta estas desventajas:
 - Pobre quien tenga que resolver la organización, pues su diseño y validación se dificultan.
 - Instrucciones muy poco frecuentes quedan obsoletas.
 - No es posible ahorrar costos (energéticos por ejemplo) si el objetivo no necesita tanta capacidad
   que la arquitectura provee.
 - El exceso de instrucciones dificulta el desarrollo y lectura de programas y documentación.

Es por esto que RISC-V se define como modular ya que no sigue esta convención, sino que tiene
estas características:
 - De base tiene un set mínimo de instrucciones que es lo suficientemente general para cualquier
   objetivo. Ya con esto los sistemas embebidos se benefician bastante, por ejemplo.
 - Si en un objectivo se necesitan instrucciones específicas, como realizar aritmética con
   números de punto flotante, la arquitectura provee sets adicionales llamados "extensiones" que
   permiten al hardware poder escalar sin desperdiciar costos adicionales, y al software de no
   tener que implementar programas adicionales.
 - Se pueden utilizar varias extensiones a la vez, ya que todas respetan los formatos de instrucción
   y los bits disponibles para definirse.

Obviamente modularizar una arquitectura se puede exagerar tanto que podría por ejemplo en la de
Orga1 tener como set mínimo las instrucciones SUB y JLE para tener una máquina de Turing
(lo chusmeé de acá https://en.wikipedia.org/wiki/One-instruction_set_computer#Subtract_and_branch_if_less_than_or_equal_to_zero)
pero esto ya sería demasiado engorroso para la programación y se necesitaría urgentemente sus extensiones.

*Ejercicio 4* Queremos agregar un flag llamado P (paridad) que nos indica si el resultado de una
operación en la ALU es par. ¿Qué cambios hacen falta hacer a Orga1SmallI para implementarlo?
Descríbalos en detalle. ¿Cómo resolvería un salto condicional (JP) por paridad? Suponga que tiene
espacio libre para la instrucciones en la memoria de la unidad de control y que puede agregar
tantas señales a la misma como hagan falta.

Respuesta:
Un número representado en sistema binario se puede saber si es par o impar viendo su dígito menos
significativo, si es 0 es par y si es 1 impar (Sin embargo, se invierte en la flag por semántica).
Luego, si quiero agregar esa flag P necesito hacer lo siguiente:
 - Dentro de la ALU, aumento a 4 bits la salida "flags".
 - Conecto el cable que va a la entrada D de ALU_OUT con un splitter que envía
   solamente el bit menos significativo.
 - Inserto un registro de un bit con las entradas:
   - NOT(Señal que sale del splitter) -> D
   - clk -> Clock
   - rst -> Clear
   - Q -> flags

Por último, para resolver el JP hay que hacer lo siguiente:
 - Dentro de la Unidad de Control, la entrada "flags" aumenta a 4 bits.
 - Creo una señal llamada "jp_microOp" que sale de la 23º señal de la ROM.
 - jp_microOp lo agrego como entrada al OR que tiene de entradas j{c,z,n}_microOp.
 - Inserto un AND con la flag P y jp_microOp como entradas.
 - La salida del AND la agrego como entrada al OR que también tiene como entradas
   salidas de otras ANDs.
 - Al archivo .ops que luego se inserta compilado en la ROM le agrego la siguiente
   instrucción:

   01100: ; JP (12)
       JP_microOp load_microOp ; suma 1 o 2 al microPC si P es 0 o 1 respectivamente
       reset_microOp           ; se levanta si se sumó 1 el microPC
       DE_enOutImm PC_load     ; se asigna el PC si se sumó 2 el microPC
       reset_microOp

*Ejercicio 5* La necesidad de realizar numerosas operaciones sobre datos estructurados en memoria parece
seguir creciendo mientras que el costo y la escala de las operaciones realizadas por el procesador
se vuelven más costosas en tiempo e infraestructura. Debido a esto se están evaluando alternativas
para realizar diversas operaciones en memoria sin tener la obligación de mover datos entre los
registros y la memoria principal.
Proponemos el uso de un controlador de memoria con las siguientes señales de control:
 - mem_op es una señal de tres bits que indican la operación a realizar
   - 000 no realiza ninguna operación
   - 001 permite guardar el valor del registro de destino (wrAddr)
   - 010 permite guardar el valor del registro de fuente (rdAddr)
   - 011 realiza una escritura en la dirección de destino desde el valor encontrado en inData
     (equivale al load de nuestra arquitectura)
   - 100 suma el valor que se encuentra en la dirección de fuente al valor que se encuentra
     en la direcicón de destino y lo guarda en la dirección de destino
   - 101 multiplica el valor que se encuentra en la dirección de fuente por el valor que se
     encuentra en la direcicón de destino y lo guarda en la dirección de destino
   - 110 limpia el valor que se encuentra en la dirección de destino
   - 111 mueve el valor que se encuentra en la dirección de fuente (rdAddr) y lo copia en la
     dirección de destino (wrAddr)
 - enOut permite volcar el valor encontrado en la direción de fuente en el registro outData    
Y las siguientes señales de datos:
 - wrAddr indica la dirección de destino (la dirección de la palabra donde realizaremos una
   escritura)
 - rdAddr indica la dirección de fuente (la dirección de la palabra donde realizaremos una
   lectura)
 - inData indica el valor de la palabra a guardar en la dirección de destino
 - outData indica el valor de la palabra a leer de la dirección de fuente

Suponiendo que las señales de control están conectadas a la unidad de control
(mem_op, enOut) y los registros de datos al bus (wrAddr, rdAddr, inData, outData):
Escriba un microprograma que permita limpiar el contenido del valor que se encuentra en la
dirección referida por el registro indicado en el operando X del decoder.

Respuesta:
